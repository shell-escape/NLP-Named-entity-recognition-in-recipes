{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "6_My. Распознавание структуры рецептов.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtSs51IgwjPG"
      },
      "source": [
        "# Named-entity recognition in recipes\r\n",
        "### Based on course [\"Нейронные сети и обработка текста\"](https://stepik.org/course/54098/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9YhQEpYDkzj"
      },
      "source": [
        "## Required libraries, functions and classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4iI_1vxK6Rs"
      },
      "source": [
        "!pip3 install livelossplot --quiet\r\n",
        "!pip3 install ipymarkup --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFvIVijxDyrJ"
      },
      "source": [
        "from google.colab import drive\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\r\n",
        "\r\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\r\n",
        "\r\n",
        "from tqdm.notebook import tqdm\r\n",
        "\r\n",
        "import datetime\r\n",
        "\r\n",
        "from copy import deepcopy\r\n",
        "\r\n",
        "from traceback import format_exc\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.utils.multiclass import unique_labels\r\n",
        "\r\n",
        "from collections import Counter\r\n",
        "\r\n",
        "from livelossplot import PlotLosses\r\n",
        "\r\n",
        "from ipymarkup import show_box_markup\r\n",
        "from ipymarkup.palette import palette, BLUE, RED, GREEN, PURPLE, BROWN, ORANGE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcLjidNsEMun"
      },
      "source": [
        "def init_random_seed(value=0):\r\n",
        "    np.random.seed(value)\r\n",
        "    torch.manual_seed(value)\r\n",
        "    torch.cuda.manual_seed(value)\r\n",
        "    torch.backends.cudnn.deterministic = True\r\n",
        "\r\n",
        "init_random_seed()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUogKU5nqK7P"
      },
      "source": [
        "def divisors(n):\r\n",
        "    i = 1\r\n",
        "    divisors = []\r\n",
        "    while i <= n**0.5:\r\n",
        "        if (n % i == 0) : \r\n",
        "            if (n / i == i):\r\n",
        "                divisors.append(i)\r\n",
        "            else:\r\n",
        "                divisors.extend([i, n // i])\r\n",
        "        i = i + 1\r\n",
        "    return sorted(divisors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyjYlcJoqLvq"
      },
      "source": [
        "def copy_data_to_device(data, device):\r\n",
        "    if torch.is_tensor(data):\r\n",
        "        return data.to(device)\r\n",
        "    elif isinstance(data, (list, tuple)):\r\n",
        "        return [copy_data_to_device(elem, device) for elem in data]\r\n",
        "    raise ValueError('Invalid data type {}'.format(type(data)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7Z2DjwLF9Y3"
      },
      "source": [
        "def form_vocabulary_and_tagset(recipes):\r\n",
        "    vocabulary, labels = set(), set()\r\n",
        "    for line in recipes:\r\n",
        "        if len(line) > 0:\r\n",
        "            word, label = line.split('\\t')\r\n",
        "            vocabulary.add(word)\r\n",
        "            labels.add(label)\r\n",
        "            \r\n",
        "    return vocabulary, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QBebl_WGhow"
      },
      "source": [
        "def prepare_data(lines):\r\n",
        "    recipes_w_tags = []\r\n",
        "    recipe, tags = [], []\r\n",
        "\r\n",
        "    for line in lines:\r\n",
        "        if len(line) > 0:\r\n",
        "            word, label = line.split('\\t')\r\n",
        "            recipe.append(word)\r\n",
        "            tags.append(label)\r\n",
        "        else:\r\n",
        "            if len(recipe) > 0:\r\n",
        "                recipes_w_tags.append((recipe, tags))\r\n",
        "            recipe, tags = [], []\r\n",
        "\r\n",
        "    return recipes_w_tags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypksYGnkEnIi"
      },
      "source": [
        "def show_markup(recipe, tags, palette_set):\r\n",
        "    mapper = lambda tag: tag[2:] if tag!='OTHER' else tag\r\n",
        "    \r\n",
        "    tags  = [mapper(tag) for tag in tags]\r\n",
        "    text  = ' '.join(recipe)\r\n",
        "    spans = []\r\n",
        "        \r\n",
        "    start, end, tag = 0, len(recipe[0]), tags[0]\r\n",
        "    \r\n",
        "    for word, ttag in zip(recipe[1:], tags[1:]): \r\n",
        "        \r\n",
        "        if tag == ttag:\r\n",
        "            end  += 1 + len(word)\r\n",
        "            \r\n",
        "        else:\r\n",
        "            span  = (start, end, tag)\r\n",
        "            spans.append(span)\r\n",
        "        \r\n",
        "            start = 1 + end\r\n",
        "            end += 1 + len(word)\r\n",
        "            tag = ttag\r\n",
        "            \r\n",
        "    span = (start, end, tag)\r\n",
        "    spans.append(span)        \r\n",
        "            \r\n",
        "    show_box_markup(text, spans, palette=palette_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv4jBayGEtL9"
      },
      "source": [
        "def tag_statistics(encoded_dataset, tags_pred):\r\n",
        "\r\n",
        "    def tag_counter(predicted, ground):\r\n",
        "        correct_tags = Counter()\r\n",
        "        ground_tags = Counter(ground)\r\n",
        "        \r\n",
        "        for tag_p, tag_g in zip(predicted, ground):\r\n",
        "            if tag_p == tag_g:\r\n",
        "                correct_tags[tag_g] += 1            \r\n",
        "        return correct_tags, ground_tags\r\n",
        "    \r\n",
        "    \r\n",
        "    total_correct, total_tags = Counter(), Counter()\r\n",
        "    \r\n",
        "    for i in range(len(encoded_dataset)):\r\n",
        "        recipe, tags = encoded_dataset[i]\r\n",
        "        tags_correct, tags_num = tag_counter(tags_pred[i], tags.tolist())\r\n",
        "        total_correct.update(tags_correct)\r\n",
        "        total_tags.update(tags_num)\r\n",
        "    del total_tags[0]\r\n",
        "    return total_correct, total_tags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFyfLjt1hKN8"
      },
      "source": [
        "def print_statistics(converter, total_correct, total_tags):\r\n",
        "    print('Statistics for correctly predicted tags:\\n')\r\n",
        "\r\n",
        "    for tag in total_tags.keys():\r\n",
        "        print('for {}:'.format(converter.indices_to_tags([tag])))\r\n",
        "        print('  correct:\\t', total_correct[tag])\r\n",
        "        print('      total:\\t',   total_tags[tag])\r\n",
        "        print('% correct:\\t', 100 * (total_correct[tag] / float(total_tags[tag])))\r\n",
        "        print()\r\n",
        "\r\n",
        "    print('----------')\r\n",
        "    print('in sum:')\r\n",
        "    print('  correct:\\t', sum(total_correct.values()))\r\n",
        "    print('      total:\\t', sum(total_tags.values()))\r\n",
        "    print('% correct:\\t', 100 * (sum(total_correct.values()) / sum(total_tags.values())))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCcfVagVEvIH"
      },
      "source": [
        "def recipe_statistics(dataset, tags_pred, limit=None):\r\n",
        "        \r\n",
        "    correct_recipes = Counter()\r\n",
        "    total_recipes = len(dataset)\r\n",
        "\r\n",
        "    for i in range(len(dataset)):\r\n",
        "        _, tags = dataset[i]\r\n",
        "        noneq_num = len([tag for tag, true_tag in zip(tags_pred[i], tags) if tag != true_tag])\r\n",
        "        if limit and noneq_num > limit:\r\n",
        "            title = 'recipes tagged with > {} errors'.format(limit)\r\n",
        "        elif noneq_num == 0:\r\n",
        "            title = 'recipes tagged without errors'\r\n",
        "        else:\r\n",
        "            title = 'recipes tagged with {} errors:'.format(noneq_num)\r\n",
        "            \r\n",
        "        correct_recipes[title] += 1\r\n",
        "    \r\n",
        "    return correct_recipes, total_recipes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hNDOsaqExSD"
      },
      "source": [
        "def plot_recipe_statistics(correct_recipes, total_recipes=None):\r\n",
        "\r\n",
        "    plt.rcdefaults()\r\n",
        "    fig, ax = plt.subplots()\r\n",
        "\r\n",
        "    descr,performance = zip(*correct_recipes.most_common())\r\n",
        "    y_pos = np.arange(len(descr))\r\n",
        "    \r\n",
        "    if total_recipes is not None:\r\n",
        "        performance = 100 * (np.array(performance) / float(total_recipes))\r\n",
        "        \r\n",
        "        ax.set_title('% of tagged recipes')\r\n",
        "        ax.set_xlabel('% of reciped')\r\n",
        "        \r\n",
        "    else:\r\n",
        "        ax.set_title('number of tagged recipes')\r\n",
        "        ax.set_xlabel('number of recipes')\r\n",
        "\r\n",
        "    ax.barh(y_pos, performance, align='center')\r\n",
        "    ax.set_yticks(y_pos)\r\n",
        "    ax.set_yticklabels(descr)\r\n",
        "    ax.invert_yaxis()\r\n",
        "\r\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs9va9PQEzNP"
      },
      "source": [
        "def plot_confusion_matrix(y_true, y_pred, classes, normalize=False, title=None, cmap=plt.cm.Blues):\r\n",
        "   \r\n",
        "    cm = confusion_matrix(y_true, y_pred, classes)\r\n",
        "    if normalize:\r\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\r\n",
        "    \r\n",
        "    fig, ax = plt.subplots(figsize=(7, 7))\r\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\r\n",
        "   \r\n",
        "    ax.figure.colorbar(im, ax=ax)\r\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\r\n",
        "           yticks=np.arange(cm.shape[0]),\r\n",
        "           xticklabels=classes, \r\n",
        "           yticklabels=classes,\r\n",
        "           title=title,\r\n",
        "           ylabel='True tag',\r\n",
        "           xlabel=\"Predicted tag\")\r\n",
        "    \r\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\r\n",
        "\r\n",
        "    fmt = '.2f' if normalize else 'd'\r\n",
        "    thresh = cm.max() / 2.\r\n",
        "    for i in range(cm.shape[0]):\r\n",
        "        for j in range(cm.shape[1]):\r\n",
        "            ax.text(j, i, format(cm[i, j], fmt), ha=\"center\", va=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\r\n",
        "    fig.tight_layout()\r\n",
        "    \r\n",
        "    return ax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HVJnxSVD8Qs"
      },
      "source": [
        "class Converter():\r\n",
        "    def __init__(self, vocabulary, tags):\r\n",
        "        self.idx_to_word = sorted(vocabulary)\r\n",
        "        self.idx_to_tag  = sorted(tags)\r\n",
        "\r\n",
        "        self.word_to_idx = {word: idx + 1 for idx, word in enumerate(self.idx_to_word)}\r\n",
        "        self.tag_to_idx = {tag: idx + 1 for idx, tag in enumerate(self.idx_to_tag)}\r\n",
        "\r\n",
        "    def words_to_index(self, words):\r\n",
        "        return torch.tensor([self.word_to_idx[w] for w in words], dtype=torch.long)\r\n",
        "    \r\n",
        "    def tags_to_index(self, words):\r\n",
        "        return torch.tensor([self.tag_to_idx[w] for w in words], dtype=torch.long)\r\n",
        "    \r\n",
        "    def indices_to_words(self, indices):\r\n",
        "        return [self.idx_to_word[i - 1] for i in indices if i != 0]\r\n",
        "    \r\n",
        "    def indices_to_tags(self, indices):\r\n",
        "        return [self.idx_to_tag[i - 1] for i in indices if i != 0]\r\n",
        "\r\n",
        "    def sample_to_index(self, sample):\r\n",
        "        return [(self.words_to_index(words), self.tags_to_index(tags)) for words, tags in sample]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B11pr4N9R05r"
      },
      "source": [
        "class LSTMTagger(nn.Module):\r\n",
        "    def __init__(self, vocab_size, tagset_size, embedding_dim=16, hidden_dim=64, num_layers=1, layer_dropout=0, emb_dropout=0):    \r\n",
        "        super(LSTMTagger, self).__init__()\r\n",
        "        self.embs = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\r\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True, dropout=layer_dropout, bidirectional=True)\r\n",
        "        self.hidden_to_tag = nn.Linear(2 * hidden_dim, tagset_size)\r\n",
        "        self.emb_dropout = nn.Dropout(emb_dropout)\r\n",
        "\r\n",
        "    def forward(self, words):\r\n",
        "        seq_lengths = list(torch.count_nonzero(words, dim=1))\r\n",
        "        words_embs = self.embs(words)\r\n",
        "        words_embs = self.emb_dropout(words_embs)\r\n",
        "        packed_words_embs = pack_padded_sequence(words_embs, seq_lengths, batch_first=True, enforce_sorted=False)\r\n",
        "        lstm_out, _ = self.lstm(packed_words_embs)\r\n",
        "        output, input_sizes = pad_packed_sequence(lstm_out, batch_first=True, total_length=words_embs.shape[1])\r\n",
        "        tag_space = self.hidden_to_tag(output)\r\n",
        "        tag_scores  = F.log_softmax(tag_space, dim=-1)\r\n",
        "        return tag_scores\r\n",
        "\r\n",
        "    def predict_tags(self, words):\r\n",
        "        model.eval()\r\n",
        "        with torch.no_grad():\r\n",
        "            tags_pred = model(words).cpu().numpy()\r\n",
        "            tags_pred = np.argmax(tags_pred, axis=-1)\r\n",
        "        return tags_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQU2lUSxZusH"
      },
      "source": [
        "class TaggerDataset(Dataset):\r\n",
        "    def __init__(self, encoded_sample):\r\n",
        "        self.encoded_words, self.encoded_tags = map(list, zip(*encoded_sample))\r\n",
        "        self.padded_encoded_words = pad_sequence(self.encoded_words, batch_first=True)\r\n",
        "        self.padded_encoded_tags = pad_sequence(self.encoded_tags, batch_first=True)\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.encoded_words)\r\n",
        "\r\n",
        "    def __getitem__(self, item):\r\n",
        "        return self.padded_encoded_words[item], self.padded_encoded_tags[item]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoRBbOv5dWS6"
      },
      "source": [
        "def batch_nllloss(pred, target):\r\n",
        "    \"\"\"\r\n",
        "    pred - BatchSize x TargetLen x VocabSize\r\n",
        "    target - BatchSize x TargetLen\r\n",
        "    \"\"\"\r\n",
        "    pred_flat = pred.view(-1, pred.shape[-1])\r\n",
        "    target_flat = target.view(-1)\r\n",
        "    return F.nll_loss(pred_flat, target_flat, ignore_index=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJspnvOLXmxQ"
      },
      "source": [
        "def train_eval_loop(model, train_dataset, val_dataset, criterion, lr=1e-3, epoch_n=100, batch_size_train=32,\r\n",
        "                    batch_size_val=32, device=None, early_stopping_patience=10, l2_reg_alpha=0, data_loader_ctor=DataLoader,\r\n",
        "                    optimizer_ctor=None, lr_scheduler_ctor=None, dataloader_workers_n=0, draw_loss=False, show_bar=False, show_lr=False):\r\n",
        "\r\n",
        "    if device is None:\r\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
        "    device = torch.device(device)\r\n",
        "    model.to(device)\r\n",
        "\r\n",
        "    if optimizer_ctor is None:\r\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_reg_alpha)\r\n",
        "    else:\r\n",
        "        optimizer = optimizer_ctor(model.parameters(), lr=lr)\r\n",
        "    \r\n",
        "    if lr_scheduler_ctor is not None:\r\n",
        "        lr_scheduler = lr_scheduler_ctor(optimizer)\r\n",
        "    else:\r\n",
        "        lr_scheduler = None\r\n",
        "\r\n",
        "    if draw_loss:\r\n",
        "        liveplot = PlotLosses()\r\n",
        "\r\n",
        "    train_dataloader = data_loader_ctor(train_dataset, batch_size=batch_size_train, num_workers=dataloader_workers_n)\r\n",
        "    val_dataloader = data_loader_ctor(val_dataset, batch_size=batch_size_val, num_workers=dataloader_workers_n)\r\n",
        "\r\n",
        "    best_val_loss = float(\"inf\")\r\n",
        "    best_epoch_i = 0\r\n",
        "    best_model = deepcopy(model)\r\n",
        "    \r\n",
        "    for epoch_i in range(epoch_n):\r\n",
        "        try:\r\n",
        "            if not draw_loss:\r\n",
        "                epoch_start = datetime.datetime.now()\r\n",
        "                print(f\"Epoch {epoch_i}\")\r\n",
        "\r\n",
        "            model.train()\r\n",
        "            mean_train_loss = 0\r\n",
        "            train_batches_n = 0\r\n",
        "\r\n",
        "            for batch_x, batch_y in tqdm(train_dataloader) if show_bar else train_dataloader:\r\n",
        "                batch_x = copy_data_to_device(batch_x, device)\r\n",
        "                batch_y = copy_data_to_device(batch_y, device)\r\n",
        "                pred = model(batch_x)\r\n",
        "                loss = criterion(pred, batch_y)\r\n",
        "\r\n",
        "                model.zero_grad()\r\n",
        "                loss.backward()\r\n",
        "\r\n",
        "                optimizer.step()\r\n",
        "\r\n",
        "                mean_train_loss += float(loss)\r\n",
        "                train_batches_n += 1\r\n",
        "\r\n",
        "            mean_train_loss /= train_batches_n\r\n",
        "\r\n",
        "            model.eval()\r\n",
        "            mean_val_loss = 0\r\n",
        "            val_batches_n = 0\r\n",
        "\r\n",
        "            with torch.no_grad():\r\n",
        "                for batch_x, batch_y in tqdm(val_dataloader) if show_bar else val_dataloader:\r\n",
        "\r\n",
        "                    batch_x = copy_data_to_device(batch_x, device)\r\n",
        "                    batch_y = copy_data_to_device(batch_y, device)\r\n",
        "\r\n",
        "                    pred = model(batch_x)\r\n",
        "                    loss = criterion(pred, batch_y)\r\n",
        "\r\n",
        "                    mean_val_loss += float(loss)\r\n",
        "                    val_batches_n += 1\r\n",
        "\r\n",
        "            mean_val_loss /= val_batches_n\r\n",
        "            \r\n",
        "            if not draw_loss:\r\n",
        "                print('{} iterations for training and {} for validation, {:0.2f} sec'.format(train_batches_n, val_batches_n,\r\n",
        "                                                           (datetime.datetime.now() - epoch_start).total_seconds()))\r\n",
        "                print('Average value of the train loss function:', mean_train_loss)\r\n",
        "                print('Average value of the validation loss function:', mean_val_loss)\r\n",
        "\r\n",
        "            if draw_loss:\r\n",
        "                liveplot.update({'mean loss': mean_train_loss, \"val_mean loss\": mean_val_loss})\r\n",
        "                liveplot.draw()\r\n",
        "\r\n",
        "            if mean_val_loss < best_val_loss:\r\n",
        "                best_epoch_i = epoch_i\r\n",
        "                best_val_loss = mean_val_loss\r\n",
        "                best_model = deepcopy(model)\r\n",
        "                if not draw_loss:\r\n",
        "                    print('New best model!')\r\n",
        "            elif epoch_i - best_epoch_i > early_stopping_patience:\r\n",
        "                print('The model has not improved over the last {} epochs, stop training'.format(\r\n",
        "                    early_stopping_patience))\r\n",
        "                break\r\n",
        "  \r\n",
        "            if lr_scheduler is not None:\r\n",
        "                if isinstance(lr_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\r\n",
        "                    lr_scheduler.step(mean_val_loss)\r\n",
        "                elif isinstance(lr_scheduler, torch.optim.lr_scheduler.StepLR):\r\n",
        "                    lr_scheduler.step()\r\n",
        "                    if show_lr:\r\n",
        "                        print(optimizer.param_groups[0]['lr'])\r\n",
        "                else:\r\n",
        "                    lr_scheduler.step()\r\n",
        "\r\n",
        "            print()\r\n",
        "        except KeyboardInterrupt:\r\n",
        "            print('Stopped early by user')\r\n",
        "            break\r\n",
        "        except Exception as ex:\r\n",
        "            print('Error while training: {}\\n{}'.format(ex, format_exc()))\r\n",
        "            break\r\n",
        "\r\n",
        "    return best_val_loss, best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BoQECEKaM54"
      },
      "source": [
        "def predict_tags_on_tokenized_dataset(model, dataset, device=None, batch_size=None, dataloader_workers_n=5):\r\n",
        "    if batch_size is None:\r\n",
        "        batch_size = len(dataset)\r\n",
        "    if device is None:\r\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
        "    results_by_batch = []\r\n",
        "    device = torch.device(device)\r\n",
        "    model.to(device)\r\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=dataloader_workers_n)\r\n",
        "    for batch_x, batch_y in dataloader:\r\n",
        "        batch_x = copy_data_to_device(batch_x, device)                    \r\n",
        "        encoded_tags = model.predict_tags(batch_x)\r\n",
        "        encoded_tags_no_padding = [list(tags_for_one_recipe[one_recipe > 0]) for tags_for_one_recipe, one_recipe in zip(encoded_tags, batch_x.cpu())]\r\n",
        "        results_by_batch.extend(encoded_tags_no_padding)\r\n",
        "\r\n",
        "    return results_by_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNtzFJa6R14c"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfFDMyW-wjPa"
      },
      "source": [
        "## Loading [recipe dataset in BIO format](https://github.com/Samsung-IT-Academy/stepik-dl-nlp/blob/master/datasets/BIO_recipe_dataset.txt):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tEcleB3zG65"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5sf35YD0DQj"
      },
      "source": [
        "datafile = \"/content/gdrive/My Drive/ML/datasets/BIO_recipe_dataset.txt\"\r\n",
        "lines = open(datafile, encoding='utf-8').read().strip().split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JG-9O0jmwjPc"
      },
      "source": [
        "## [Building vocabulary and labels](#scrollTo=I7Z2DjwLF9Y3&line=1&uniqifier=1):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdgurhnywjPc"
      },
      "source": [
        "vocabulary, labels = form_vocabulary_and_tagset(lines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XO1NhQDhoE57"
      },
      "source": [
        "## [Combine](#scrollTo=0QBebl_WGhow&line=1&uniqifier=1) sentenses and their labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aldLA2O3wjPd"
      },
      "source": [
        "recipes_w_tags = prepare_data(lines)\n",
        "\n",
        "len(recipes_w_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyHVKxknwjPd"
      },
      "source": [
        "test_recipe, test_tags = recipes_w_tags[0]\n",
        "palette_set = palette(NAME=BLUE, UNIT=RED, QTY=GREEN, RANGE_END=GREEN, INDEX=PURPLE, COMMENT=ORANGE, OTHER=BROWN)\n",
        "show_markup(test_recipe, test_tags, palette_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pv7ckISHwjPe"
      },
      "source": [
        "## [Convert](#scrollTo=_HVJnxSVD8Qs&line=1&uniqifier=1) words and tags to indices and vice versa:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jHIj_0VwjPe"
      },
      "source": [
        "converter = Converter(vocabulary, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1touHjstwjPe"
      },
      "source": [
        "encoded_recipe = converter.words_to_index(test_recipe)\n",
        "encoded_tags = converter.tags_to_index(test_tags)\n",
        "\n",
        "print(encoded_recipe)\n",
        "print(encoded_tags)\n",
        "print()\n",
        "\n",
        "decoded_recipe = converter.indices_to_words(encoded_recipe)\n",
        "decoded_tags = converter.indices_to_tags(encoded_tags)\n",
        "\n",
        "show_markup(decoded_recipe, decoded_tags, palette_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0jBJtRzomZ7"
      },
      "source": [
        "## Preparing train and validation [datasets](#scrollTo=OQU2lUSxZusH&line=1&uniqifier=1):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqFepyMXY-ml"
      },
      "source": [
        "np.random.shuffle(recipes_w_tags)\r\n",
        "\r\n",
        "TRAIN_SPLIT = int(len(recipes_w_tags) * 0.7)\r\n",
        "train_sample = converter.sample_to_index(recipes_w_tags[:TRAIN_SPLIT])\r\n",
        "val_sample = converter.sample_to_index(recipes_w_tags[TRAIN_SPLIT:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zFyF66fwjPe"
      },
      "source": [
        "train_dataset = TaggerDataset(train_sample)\n",
        "val_dataset = TaggerDataset(val_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvQ2sY4cpI3D"
      },
      "source": [
        "## Finding the appropriate batch sizes for train and validation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ye1RoB2wqHII"
      },
      "source": [
        "print(f\"divisors of train dataset size ({len(train_dataset)}) are {divisors(len(train_dataset))}\")\r\n",
        "print(f\"divisors of val dataset size ({len(val_dataset)}) are {divisors(len(val_dataset))}\")\r\n",
        "\r\n",
        "batch_size_train = 793\r\n",
        "batch_size_val = 2991"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWJ6JZywwjPf"
      },
      "source": [
        "## [LSTM model](#scrollTo=B11pr4N9R05r&line=1&uniqifier=1):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvhOdNwJwjPf"
      },
      "source": [
        "VOCAB_SIZE = len(converter.word_to_idx) + 1\n",
        "TAGSET_SIZE = len(converter.tag_to_idx) + 1\n",
        "EMBEDDING_DIM = 200\n",
        "HIDDEN_DIM = 400\n",
        "NUM_LAYERS = 6\n",
        "LAYER_DROPOUT = 0.5\n",
        "EMB_DROPOUT = 0.85\n",
        "\n",
        "model = LSTMTagger(VOCAB_SIZE, TAGSET_SIZE, EMBEDDING_DIM, HIDDEN_DIM, NUM_LAYERS, LAYER_DROPOUT, EMB_DROPOUT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zchqxwqlpf0V"
      },
      "source": [
        "## [Training](#scrollTo=tJspnvOLXmxQ&line=1&uniqifier=1):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieFwD0rnwjPf"
      },
      "source": [
        "lr_scheduler = lambda optim: \\\n",
        "    torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=5, factor=0.5, verbose=True)\n",
        "\n",
        "#lr_scheduler = lambda optim: \\\n",
        "#    torch.optim.lr_scheduler.StepLR(optim, step_size=5, gamma=0.9)\n",
        "\n",
        "best_val_loss, best_torch_transf_model = train_eval_loop(model,\n",
        "                                                         train_dataset,\n",
        "                                                         val_dataset,\n",
        "                                                         batch_nllloss,\n",
        "                                                         lr=5e-4,\n",
        "                                                         epoch_n=1000,\n",
        "                                                         batch_size_train=batch_size_train,\n",
        "                                                         batch_size_val=batch_size_val,\n",
        "                                                         early_stopping_patience=20,\n",
        "                                                         lr_scheduler_ctor=lr_scheduler,\n",
        "                                                         draw_loss=False,\n",
        "                                                         show_bar=True,\n",
        "                                                         dataloader_workers_n=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLki1ob2pu2Y"
      },
      "source": [
        "## Some examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uY-lWi-cLxaG"
      },
      "source": [
        "size_for_demonstrate = 10\r\n",
        "demonstrative_dataset = Subset(val_dataset, indices=np.random.choice(len(val_dataset), size_for_demonstrate))\r\n",
        "demonstrative_tags_pred = predict_tags_on_tokenized_dataset(model, demonstrative_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvaTSEnyUMu5"
      },
      "source": [
        "for i in range(size_for_demonstrate):\r\n",
        "    recipe, tags = demonstrative_dataset[i]\r\n",
        "    \r\n",
        "    print('Ground truth')\r\n",
        "    show_markup(converter.indices_to_words(recipe), converter.indices_to_tags(tags), palette_set)\r\n",
        "\r\n",
        "    print('Prediction:')\r\n",
        "    show_markup(converter.indices_to_words(recipe), converter.indices_to_tags(demonstrative_tags_pred[i]), palette_set)\r\n",
        "    \r\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFe3_BD2wjPj"
      },
      "source": [
        "## Statistics on validation set:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGPIU_o7wjPj"
      },
      "source": [
        "### [Number of correctly predicted tags](#scrollTo=Nv4jBayGEtL9&line=1&uniqifier=1):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEK7sAgjdBC7"
      },
      "source": [
        "val_tags_pred = predict_tags_on_tokenized_dataset(model, val_dataset, device=None, batch_size=2991)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuzSLz6mwjPj"
      },
      "source": [
        "total_val_correct, total_val_tags = tag_statistics(val_dataset, val_tags_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm-Nb_ZJjhkW"
      },
      "source": [
        "print_statistics(converter, total_val_correct, total_val_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fH4rKtVwjPk"
      },
      "source": [
        "### [Confusion Matrix](#scrollTo=Cs9va9PQEzNP&line=1&uniqifier=1):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89Ua2RgmwjPm"
      },
      "source": [
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "for i in range(len(val_dataset)):\n",
        "    _, tags = val_dataset[i]\n",
        "    y_pred += converter.indices_to_tags(val_tags_pred[i])\n",
        "    y_true += converter.indices_to_tags(tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh3uXwgVwjPn"
      },
      "source": [
        "plot_confusion_matrix(y_true, y_pred, classes=converter.indices_to_tags(total_val_tags.keys()), title='Confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BpViIGGwjPn"
      },
      "source": [
        "plot_confusion_matrix(y_true, y_pred, classes=converter.indices_to_tags(total_val_tags.keys()), normalize=True, \n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRceymuzwjPn"
      },
      "source": [
        "### [Number of correctly predicted recipes](#scrollTo=yCcfVagVEvIH&line=1&uniqifier=1):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNzICxo0wjPn"
      },
      "source": [
        "correct_recipes, total_recipes = recipe_statistics(val_dataset, val_tags_pred, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKV-Ev-7wjPo"
      },
      "source": [
        "plot_recipe_statistics(correct_recipes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-y-25Kg5yVd"
      },
      "source": [
        "plot_recipe_statistics(correct_recipes, total_recipes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk9iJA3vK4wd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}